{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTR0VzOm2B5d"
   },
   "source": [
    "# 0. Marking and Guidelines\n",
    "---\n",
    "***IMPORTANT***\n",
    "\n",
    "> The **attendance** and **active participation** in the **lab sessions** is **strongly recommended** and will be considered for grading.\n",
    ">\n",
    "> Save a copy of this notebook into your Drive before you start\n",
    "> \n",
    "> Please attempt all the **questions** marked for your **group** (Part II ✅ | Part III/MPhil ✅).\n",
    "> \n",
    "> Continue to **\"Part 2\"** after you are done with this **\"Part 1\"**.\n",
    ">\n",
    "> Please, provide your answers in a **new cell below the question cell**. You can make as many new cells as you need.\n",
    "\n",
    "Please submit a `.zip` file, containing both parts, consisting of:\n",
    "1. A text file with a **publicly** visible link to your notebooks in GitHub.\n",
    "2. A **downloaded copy** (`.ipynb`) of your notebooks or your zipped cloned GitHub repo. You may treat these as a report---we will not be re-executing the code you used to produce the answers unless required.\n",
    "\n",
    "\n",
    "Feel free to attempt more in case you find yourself enjoying the material!\n",
    "If you have any questions, please ask them to the teaching assistants.\n",
    "Are you interested in knowing more about federated learning and related topics? Reach out to the teaching assistants for additional resources and ask more about the current research projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M0eSNvNJFrjt"
   },
   "source": [
    "## 1. Introduction.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMqp_FvE2B5f"
   },
   "source": [
    "Welcome to the first lab in our Federated Learning (FL) course.\n",
    "This series of labs intends to introduce you to the practice of constructing Federated Learning systems and understand their peculiarities compared to standard distributed learning systems.\n",
    "The most common form of FL, cross-device FL, is concerned with collaboratively training models on edge devices or \"clients\" using their private data sources without involving direct exchange of training samples.\n",
    "As such, FL may:\n",
    "- Reduce communication costs (compared to standard training approaches) by only sharing model parameters.\n",
    "- Distribute computation across an untapped pool of previously unused devices, such as personal smartphones, laptops, and/or workstations.\n",
    "- Partially preserve privacy by construction, as private data is never exchange and never leaves the private domain from which it is collected.\n",
    "\n",
    "A typical server-client FL system maintains a centralised server that synchronises training across iterations of rounds---the FL equivalent of epochs. A round generally proceeds as follows:\n",
    "1. At the beginning of a round, the server sends a copy of the federated model to each client.\n",
    "2. The clients then train their copy of the model on the private data they hold and send the post-training model updates to the server.\n",
    "3. The server then aggregates all the client models to form a single federated model update which it applies before the next round. The most common means of aggregation is Federated Averaging which merges model parameters via simple weighted averaging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FhnE5-YklGrK"
   },
   "source": [
    "![fl_system_diagram](../assets/fl_system_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvDvRvsvN80X"
   },
   "source": [
    "To a more significant extent than other machine learning (ML) fields, FL has historically been driven by practical considerations rather than theoretical results.\n",
    "Some of the most critical practical concerns are related to the following:\n",
    "- Communication costs involved in training models in a highly distributed fashion across edge devices.\n",
    "- The underlying non-standardised hardware of clients within the federated network.\n",
    "- Highly divergent data distributions across clients.\n",
    "\n",
    "Such issues cannot be easily addressed, given FL's privacy and scale constraints, as persistent data on specific clients may not be trackable.\n",
    "In a worst-case setting, a single client may only participate in training once for cross-device FL with (tens of) millions of potential devices.\n",
    "\n",
    "In this lab session, we will use a realistic FL dataset to exemplify how such problems arise when ML is taken from a centralized or standard distributed setting to a federated one.\n",
    "Specific questions we will look at include the following:\n",
    "- How centralized ML can be modelled as FL with a single client and how to build a client abstraction capable of both.\n",
    "- How the federated and local optimization objectives of FL interact between each other and how different settings on the server/client side may impact convergence.\n",
    "\n",
    "To do so, we shall use the [Flower](https://flower.ai/) FL framework. The design of Flower is meant to allow for a fairly direct mapping between simulation and production FL scenarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zeAdW4nnSv5"
   },
   "source": [
    "![flower](../assets/flower.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m45tcB_gL0pw"
   },
   "source": [
    "## 2. Building a client.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qvxdivaBODPZ"
   },
   "source": [
    "Rather than beginning with a complete standard centralised ML baseline, we will treat centralised ML as a particular case of FL--a single client holding the entire (centralised) dataset.\n",
    "\n",
    "For the rest of our lab sessions, a client shall represent an abstraction which:\n",
    "- Encapsulates the data available on a particular device involved in FL.\n",
    "- Trains a model it receives on that local (train) dataset.\n",
    "- Can test models it receives on its local (test) dataset.\n",
    "\n",
    "By the end of this section, you will have constructed such a client abstraction and trained a model on a full-scale dataset.\n",
    "Later work shall merely involve connecting multiple such clients in a federated network using the Flower framework.\n",
    "\n",
    "To begin, we will need to install some dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XenFLb3FMF0s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/Iacob-Alexandru-Andrei/flower.git@teaching\n",
      "  Cloning https://github.com/Iacob-Alexandru-Andrei/flower.git (to revision teaching) to /private/var/folders/6j/51pt41xs611cqzmtybytnss40000gn/T/pip-req-build-7mpbh1_e\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/Iacob-Alexandru-Andrei/flower.git /private/var/folders/6j/51pt41xs611cqzmtybytnss40000gn/T/pip-req-build-7mpbh1_e\n",
      "  Running command git checkout -b teaching --track origin/teaching\n",
      "  Switched to a new branch 'teaching'\n",
      "  Branch 'teaching' set up to track remote branch 'teaching' from 'origin'.\n",
      "  Resolved https://github.com/Iacob-Alexandru-Andrei/flower.git to commit 1c4fcc1d4a6e8022ddf6f94ebedef1b8e70e0fc4\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting torch\n",
      "  Downloading torch-2.2.2-cp310-none-macosx_10_9_x86_64.whl.metadata (25 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.17.2-cp310-cp310-macosx_10_13_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting ray==2.6.3\n",
      "  Downloading ray-2.6.3-cp310-cp310-macosx_10_15_x86_64.whl.metadata (12 kB)\n",
      "Collecting click>=7.0 (from ray==2.6.3)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting filelock (from ray==2.6.3)\n",
      "  Using cached filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting jsonschema (from ray==2.6.3)\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray==2.6.3)\n",
      "  Downloading msgpack-1.1.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: packaging in /Users/macbook/.local/lib/python3.10/site-packages (from ray==2.6.3) (24.2)\n",
      "Collecting protobuf!=3.19.5,>=3.15.3 (from ray==2.6.3)\n",
      "  Using cached protobuf-5.29.3-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Collecting pyyaml (from ray==2.6.3)\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-macosx_10_9_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting aiosignal (from ray==2.6.3)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting frozenlist (from ray==2.6.3)\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (13 kB)\n",
      "Collecting requests (from ray==2.6.3)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting grpcio>=1.42.0 (from ray==2.6.3)\n",
      "  Downloading grpcio-1.70.0-cp310-cp310-macosx_12_0_universal2.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /Users/macbook/Desktop/L361/L361-Federated-Learning/.conda/lib/python3.10/site-packages (from ray==2.6.3) (2.2.2)\n",
      "Collecting cryptography<42.0.0,>=41.0.2 (from flwr==1.7.0)\n",
      "  Using cached cryptography-41.0.7-cp37-abi3-macosx_10_12_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting iterators<0.0.3,>=0.0.2 (from flwr==1.7.0)\n",
      "  Using cached iterators-0.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting numpy>=1.19.3 (from ray==2.6.3)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-macosx_10_9_x86_64.whl.metadata (61 kB)\n",
      "Collecting protobuf!=3.19.5,>=3.15.3 (from ray==2.6.3)\n",
      "  Using cached protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Collecting pycryptodome<4.0.0,>=3.18.0 (from flwr==1.7.0)\n",
      "  Using cached pycryptodome-3.21.0-cp36-abi3-macosx_10_9_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/macbook/.local/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Collecting sympy (from torch)\n",
      "  Using cached sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/macbook/Desktop/L361/L361-Federated-Learning/.conda/lib/python3.10/site-packages (from torchvision) (11.1.0)\n",
      "Collecting cffi>=1.12 (from cryptography<42.0.0,>=41.0.2->flwr==1.7.0)\n",
      "  Downloading cffi-1.17.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-macosx_10_9_universal2.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema->ray==2.6.3)\n",
      "  Using cached attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->ray==2.6.3)\n",
      "  Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema->ray==2.6.3)\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema->ray==2.6.3)\n",
      "  Downloading rpds_py-0.22.3-cp310-cp310-macosx_10_12_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->ray==2.6.3)\n",
      "  Downloading charset_normalizer-3.4.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->ray==2.6.3)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->ray==2.6.3)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->ray==2.6.3)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography<42.0.0,>=41.0.2->flwr==1.7.0)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Downloading ray-2.6.3-cp310-cp310-macosx_10_15_x86_64.whl (58.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading torch-2.2.2-cp310-none-macosx_10_9_x86_64.whl (150.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.8/150.8 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.17.2-cp310-cp310-macosx_10_13_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached cryptography-41.0.7-cp37-abi3-macosx_10_12_x86_64.whl (2.9 MB)\n",
      "Downloading grpcio-1.70.0-cp310-cp310-macosx_12_0_universal2.whl (11.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached iterators-0.0.2-py3-none-any.whl (3.9 kB)\n",
      "Downloading msgpack-1.1.0-cp310-cp310-macosx_10_9_x86_64.whl (84 kB)\n",
      "Downloading numpy-1.26.4-cp310-cp310-macosx_10_9_x86_64.whl (20.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "Using cached pycryptodome-3.21.0-cp36-abi3-macosx_10_9_x86_64.whl (1.6 MB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.5.0-cp310-cp310-macosx_10_9_x86_64.whl (54 kB)\n",
      "Using cached filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
      "Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.2-cp310-cp310-macosx_10_9_x86_64.whl (184 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "Using cached attrs-25.1.0-py3-none-any.whl (63 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Downloading cffi-1.17.1-cp310-cp310-macosx_10_9_x86_64.whl (182 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp310-cp310-macosx_10_9_universal2.whl (198 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp310-cp310-macosx_10_9_universal2.whl (14 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.22.3-cp310-cp310-macosx_10_12_x86_64.whl (359 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Building wheels for collected packages: flwr\n",
      "  Building wheel for flwr (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for flwr: filename=flwr-1.7.0-py3-none-any.whl size=231058 sha256=1dd4026e953cc84734a76152ffe91c9b02b5eb974fb66c6c7a052ce811b12377\n",
      "  Stored in directory: /private/var/folders/6j/51pt41xs611cqzmtybytnss40000gn/T/pip-ephem-wheel-cache-2_c3zx93/wheels/2b/16/bc/a3226e433191960f0d4bd720dc54b8b283b50fb166fe151daa\n",
      "Successfully built flwr\n",
      "Installing collected packages: mpmath, urllib3, sympy, rpds-py, pyyaml, pycryptodome, pycparser, protobuf, numpy, networkx, msgpack, MarkupSafe, iterators, idna, grpcio, fsspec, frozenlist, filelock, click, charset-normalizer, certifi, attrs, requests, referencing, jinja2, cffi, aiosignal, torch, jsonschema-specifications, cryptography, torchvision, jsonschema, flwr, ray\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.2\n",
      "    Uninstalling numpy-2.2.2:\n",
      "      Successfully uninstalled numpy-2.2.2\n",
      "Successfully installed MarkupSafe-3.0.2 aiosignal-1.3.2 attrs-25.1.0 certifi-2025.1.31 cffi-1.17.1 charset-normalizer-3.4.1 click-8.1.8 cryptography-41.0.7 filelock-3.17.0 flwr-1.7.0 frozenlist-1.5.0 fsspec-2025.2.0 grpcio-1.70.0 idna-3.10 iterators-0.0.2 jinja2-3.1.5 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 mpmath-1.3.0 msgpack-1.1.0 networkx-3.4.2 numpy-1.26.4 protobuf-3.20.3 pycparser-2.22 pycryptodome-3.21.0 pyyaml-6.0.2 ray-2.6.3 referencing-0.36.2 requests-2.32.3 rpds-py-0.22.3 sympy-1.13.3 torch-2.2.2 torchvision-0.17.2 urllib3-2.3.0\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://formulae.brew.sh/api/formula.jws.json\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://formulae.brew.sh/api/cask.jws.json\u001b[0m\n",
      "\u001b[33mWarning:\u001b[0m tree 2.2.1 is already installed and up-to-date.\n",
      "To reinstall 2.2.1, run:\n",
      "  brew reinstall tree\n"
     ]
    }
   ],
   "source": [
    "# `pip` could produce some errors. Do not worry about them.\n",
    "# The execution has been verified; it's working anyway.\n",
    "! pip install --quiet --upgrade \"pip\"\n",
    "! pip install --quiet matplotlib tqdm seaborn\n",
    "! pip install git+https://github.com/Iacob-Alexandru-Andrei/flower.git@teaching \\\n",
    "    torch torchvision ray==\"2.6.3\"\n",
    "# The following is just needed to show the folder tree\n",
    "# ! apt-get install -qq tree\n",
    "! brew install tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiW6ObflQhSi"
   },
   "source": [
    "Our first client abstraction shall be as simple as possible and will require adjustment to match the structure that the framework expects.\n",
    "However, it shall be conceptually identical and require only light API changes.\n",
    "\n",
    "In the next few cells, we will just import the required modules and instantiate some useful function and objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/macbook/.local/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/macbook/.local/lib/python3.10/site-packages (from ipywidgets) (8.32.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/macbook/.local/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.12 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.12 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: decorator in /Users/macbook/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: exceptiongroup in /Users/macbook/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/macbook/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/macbook/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/macbook/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/macbook/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/macbook/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /Users/macbook/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /Users/macbook/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/macbook/.local/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/macbook/.local/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/macbook/.local/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/macbook/.local/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/macbook/.local/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Users/macbook/.local/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n",
      "Downloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.5 jupyterlab-widgets-3.0.13 widgetsnbextension-4.0.13\n"
     ]
    }
   ],
   "source": [
    "! pip install -U ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "eO7LWfu4RL7a"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "import tarfile\n",
    "from typing import Any\n",
    "from logging import INFO\n",
    "from abc import abstractmethod\n",
    "from collections.abc import Sequence, Callable\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from PIL.Image import Image as ImageType\n",
    "from torch.nn import Module\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from enum import IntEnum\n",
    "from flwr.common import log\n",
    "\n",
    "\n",
    "# Add new seeds here for easy autocomplete\n",
    "class Seeds(IntEnum):\n",
    "    \"\"\"Seeds for reproducibility.\"\"\"\n",
    "\n",
    "    DEFAULT = 1337\n",
    "\n",
    "\n",
    "np.random.seed(Seeds.DEFAULT)\n",
    "random.seed(Seeds.DEFAULT)\n",
    "torch.manual_seed(Seeds.DEFAULT)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "PathType = Path | str | None\n",
    "\n",
    "\n",
    "def get_device() -> str:\n",
    "    \"\"\"Get the device (cuda, mps, cpu).\"\"\"\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "        device = \"mps\"\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "fa-jqHRaQ1C2"
   },
   "outputs": [],
   "source": [
    "class SimpleClient:\n",
    "    \"\"\"Simple client class for federated learning.\"\"\"\n",
    "\n",
    "    def __init__(self, cid: int, partition_dir: Path) -> None:\n",
    "        \"\"\"\n",
    "        Init the client with its unique id and the directory from which it loads data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            cid (int): Unique client id for a client used to map it to its data\n",
    "                partition\n",
    "            partition_dir (Path): The directory containing data for each\n",
    "                client/client id\n",
    "        \"\"\"\n",
    "        self.cid: str = str(cid)\n",
    "        self.partition_dir: Path = partition_dir\n",
    "        self.device: str = get_device()\n",
    "\n",
    "    def fit(self, net: Module, config: dict[str, Any]) -> tuple[Module, int, dict]:\n",
    "        \"\"\"Receive and train a model on the local client data.\n",
    "\n",
    "        It uses parameters from the config dict\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            net (Module): Pytorch model\n",
    "            config (Dict[str, Any]): Dictionary describing the training parameters\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            Tuple[Module, int, dict]: Returns the updated model, the size of the local\n",
    "                dataset and (optionally) other metrics\n",
    "        \"\"\"\n",
    "        net = deepcopy(net)\n",
    "        net.to(self.device)\n",
    "        train_loader: DataLoader = self._create_data_loader(config, name=\"train\")\n",
    "        self._train(net, train_loader=train_loader, config=config)\n",
    "        return net, len(train_loader), {}\n",
    "\n",
    "    def evaluate(self, net: Module, config: dict[str, Any]) -> tuple[float, int, dict]:\n",
    "        \"\"\"Receive and test a model on the local client data.\n",
    "\n",
    "        It uses parameters from the config dict.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            net (Module): Pytorch model\n",
    "            config (Dict[str, Any]): Dictionary describing the test parameters\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            Tuple[float, int, dict]: Returns the loss accumulate during test, the size\n",
    "                of the local dataset and other metrics such as accuracy\n",
    "        \"\"\"\n",
    "        net = deepcopy(net)\n",
    "        net.to(self.device)\n",
    "        test_loader: DataLoader = self._create_data_loader(config, name=\"test\")\n",
    "        loss, accuracy = self._test(net, test_loader=test_loader, config=config)\n",
    "        return loss, len(test_loader), {\"local_accuracy\": accuracy}\n",
    "\n",
    "    def _create_data_loader(self, config: dict[str, Any], name: str) -> DataLoader:\n",
    "        \"\"\"Create the data loader using the specified config parameters.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            config (Dict[str, any]): Dictionary containing dataloader and dataset\n",
    "                parameters\n",
    "            name (str): Load the training or testing set for the client\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            DataLoader: A pytorch dataloader iterable for training/testing\n",
    "        \"\"\"\n",
    "        batch_size: int = config[\"batch_size\"]\n",
    "        num_workers: int = config[\"num_workers\"]\n",
    "        dataset = self._load_dataset(name, config)\n",
    "        return DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=name != \"test\",\n",
    "        )\n",
    "\n",
    "    # All methods from here on are task-specific\n",
    "    # And need to be implemented in a later stage\n",
    "    @abstractmethod\n",
    "    def _load_dataset(self, name: str, config: dict[str, Any]) -> Dataset:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _train(\n",
    "        self, net: Module, train_loader: DataLoader, config: dict[str, Any]\n",
    "    ) -> float:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _test(\n",
    "        self, net: Module, test_loader: DataLoader, config: dict[str, Any]\n",
    "    ) -> tuple[float, float]:\n",
    "        pass\n",
    "\n",
    "\n",
    "def fit_client_seeded(\n",
    "    client: SimpleClient,\n",
    "    params: Module,\n",
    "    conf: dict[str, Any],\n",
    "    seed: Seeds = Seeds.DEFAULT,\n",
    "    **kwargs: Any,\n",
    ") -> tuple[Module, int, dict]:\n",
    "    \"\"\"Wrap to always seed client training.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    return client.fit(params, conf, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AfcgBtrhVtAo"
   },
   "source": [
    "This client covers all the previously stated functionality; it can:\n",
    "- Associate a given dataset/dataset partition to itself based on the `data_dir` and `cid` combination\n",
    "- Train any model provided to its `fit` function on the local training set\n",
    "- Evaluate any model on the local test set.\n",
    "\n",
    "To get this client training, we need to fill in the necessary gaps: the dataset loading procedure, the model, the training procedure and the testing procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPf2tk1P2B5l"
   },
   "source": [
    "---\n",
    "\n",
    "**Question 1 (Part II ✅ | Part III/MPhil ✅):**\n",
    "\n",
    "(These are meant to be conceptual questions. You should provide written answers for these. **No more than 3 sentences each**. **No code** is needed)\n",
    "\n",
    "1. What is the time complexity of transmitting models to-and-from the client?\n",
    "2. Give at least two examples of machine learning and data science techniques you cannot apply since data is kept private on single clients.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1 Answer:**\n",
    "\n",
    "1. The complexity of transmitting models to-and-from the client is O(n) where n is the number of parameters in the model. Knowing that the size of the model is proportional to the number of parameters, sending it to any/both direction will have O(n) complexity. However, due to the sum rule of big O notation, stating that if f(n) = O(h(n)) and g(n) = O(h(n)) then f(n) + g(n) = O(h(n)), hence the complexity of transmitting models to-and-from the client is O(n).\n",
    "\n",
    "\n",
    "2.\n",
    "    - Support vector machine (SVM): Support vector machine can not be used since calculating the hyperplane requires all the support vectors –– the data points closest to the hyperplane/ on the margin (globally) –– which might not be present in all the clients hence resulting in a suboptimal/incorrect hyperplane(s).\n",
    "    - K-means clustering: K-means clustering cannot be used since it requires calculating the mean of the data points in each cluster and assigning the data points to the cluster with the closest mean. However, since the data is kept private on single clients, the mean of the different clusters would depend on the data points in the client's dataset which might not be representative of the entire dataset.\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zocsNC84Wk_l"
   },
   "source": [
    "## 3. Loading the federated dataset.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NhUGGSrfkrJ"
   },
   "source": [
    "We have chosen to use the FEMNIST dataset originally published in [LEAF](https://arxiv.org/abs/1812.01097) for all of our labs due to its naturally heterogeneous properties.\n",
    "Most FL examples rely on a centralised dataset such as CIFAR-10, which is artificially partitioned to fit an FL context.\n",
    "FEMNIST is an image dataset with 28×28 greyscale images split into 62 distinct classes.\n",
    "We shall initially treat it as a centralised dataset.\n",
    "However, its federated nature will be helpful later on.\n",
    "\n",
    "It is, by default, partitioned based on the creator of a specific image, thus modelling a realistic data-generation scenario.\n",
    "A complete list of its statistics may be found on the [LEAF Website](https://leaf.cmu.edu/).\n",
    "\n",
    "We will extensively discuss federated datasets during the next lab.\n",
    "In this session, we will skip such discussions to spend more time on \"federating\" a centralised model.\n",
    "The following few cells will provide all the relevant functions and objects to load the FEMNIST dataset.\n",
    "Also, some **optional** insights will be given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "xDpybqNURmr6"
   },
   "outputs": [],
   "source": [
    "home_dir = Path.cwd()\n",
    "dataset_dir: Path = home_dir / \"femnist\"\n",
    "data_dir: Path = dataset_dir / \"data\"\n",
    "centralized_partition: Path = dataset_dir / \"client_data_mappings\" / \"centralized\"\n",
    "centralized_mapping: Path = dataset_dir / \"client_data_mappings\" / \"centralized\" / \"0\"\n",
    "federated_partition: Path = dataset_dir / \"client_data_mappings\" / \"fed_natural\"\n",
    "\n",
    "# Decompress dataset\n",
    "if not dataset_dir.exists():\n",
    "    with tarfile.open(home_dir / \"femnist.tar.gz\", \"r:gz\") as tar:\n",
    "        tar.extractall(path=home_dir)\n",
    "    log(INFO, \"Dataset extracted in %s\", dataset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UiMa5eYORmr6"
   },
   "source": [
    "You can **optionally** execute the following cell to look at the folder tree induced by unzipping the compressed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "FR92a5uyRmr6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m./\u001b[0m\n",
      "├── \u001b[01;34mcommon\u001b[0m\n",
      "│   └── \u001b[01;34m__pycache__\u001b[0m\n",
      "├── \u001b[01;34mfemnist\u001b[0m\n",
      "│   ├── \u001b[01;34mclient_data_mappings\u001b[0m\n",
      "│   │   ├── \u001b[01;34mcentralized\u001b[0m\n",
      "│   │   └── \u001b[01;34mfed_natural\u001b[0m\n",
      "│   └── \u001b[01;34mdata\u001b[0m\n",
      "│       ├── \u001b[01;34mtest\u001b[0m\n",
      "│       ├── \u001b[01;34mtrain\u001b[0m\n",
      "│       └── \u001b[01;34mval\u001b[0m\n",
      "└── \u001b[01;34mhistories\u001b[0m\n",
      "\n",
      "12 directories\n"
     ]
    }
   ],
   "source": [
    "# Showing resulting folder tree\n",
    "! tree -dC -L 3 ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-70unJnRmr6"
   },
   "source": [
    "For those of you gifted with eager curiosity, you can find the [Jupyter notebook](https://drive.google.com/file/d/1-I0uPPzm1ONlLD-u4XCFGqUgz6KPJzDe/view?usp=share_link) used to create this dataset from the version publicly available from TensorFlow Federated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moqCXNdjRmr6"
   },
   "source": [
    "We have thus downloaded two different partitions of the FEMNIST dataset.\n",
    "We will first use the \"centralised\" partition, in which we have distributed all the samples to one client. The second is the \"natural\" partition, in which the images/samples have been divided by writers.\n",
    "\n",
    "Samples have been collected once in the `data` folder, composed of three subfolders- `train`, `test` and `val`-, each containing one file for each sample in those sets. Then, it is the `client_data_mappings` folder that contains the relevant structure, composed of subfolders and `.csv` files, each describing the partitions. In fact, for each client, a `train.csv` and a `test.csv` are provided, containing a row for each sample in the client set that reports `client_id`, `sample_path`, `sample_id`, `sample_label`. It is worth mentioning that while train and test sets have been composed of the same clients, the validation set has been composed of different clients. That is why the only `val.csv` contained in this folder structure is under the centralised partition.\n",
    "\n",
    "The number of clients composing the train and test sets is 3230, while the number of clients composing the `val` set is 170. The splitting has been chosen to make the validation step quick."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muCGzjZ9qWoj"
   },
   "source": [
    "## 4. Centralized ML\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHmJIyUsWi7O"
   },
   "source": [
    "We will begin with our centralised “partition”. We then use the entire `train.csv` and `test.csv` contained in `client_data_mappings/centralized/0`. For a large section of FL tasks, the centralised baseline represents the upper limit of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "wgSy30y6n8hR"
   },
   "outputs": [],
   "source": [
    "class FEMNIST(Dataset):\n",
    "    \"\"\"Dataset class for the FEMNIST dataset.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        mapping: Path,\n",
    "        data_dir: Path = data_dir,\n",
    "        name: str = \"train\",\n",
    "        transform: Callable[[ImageType], Any] | None = None,\n",
    "        target_transform: Callable[[int], Any] | None = None,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialise the FEMNIST dataset.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            mapping (Path): path to the mapping folder containing the .csv files.\n",
    "            data_dir (Path): path to the dataset folder. Defaults to data_dir.\n",
    "            name (str): name of the dataset to load, train or test.\n",
    "            transform (Callable[[ImageType], Any] | None, optional): transform function\n",
    "                to be applied to the ImageType object. Defaults to None.\n",
    "            target_transform (Callable[[int], Any] | None, optional): transform function\n",
    "                to be applied to the label. Defaults to None.\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.mapping = mapping\n",
    "        self.name = name\n",
    "\n",
    "        self.data: Sequence[tuple[str, int]] = self._load_dataset()\n",
    "        self.transform: Callable[[ImageType], Any] | None = transform\n",
    "        self.target_transform: Callable[[int], Any] | None = target_transform\n",
    "\n",
    "    def __getitem__(self, index) -> tuple[Any, Any]:  # noqa: ANN001\n",
    "        \"\"\"Get a sample respecting PyTorch directives.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            index : index of the sample.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            Tuple[Any, Any]: couple (sample, label).\n",
    "        \"\"\"\n",
    "        sample_path, label = self.data[index]\n",
    "\n",
    "        # Convert to the full path\n",
    "        full_sample_path: Path = self.data_dir / self.name / sample_path\n",
    "\n",
    "        img: ImageType = Image.open(full_sample_path).convert(\"L\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Get the length of the dataset as the number of samples.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            int: the length of the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def _load_dataset(self) -> Sequence[tuple[str, int]]:\n",
    "        \"\"\"Load the paths and labels of the partition.\n",
    "\n",
    "        Preprocess the dataset for faster future loading,\n",
    "        if opened for the first time.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "            ValueError: raised if the mapping file does not exist.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            Sequence[tuple[str, int]]: partition asked as a sequence of\n",
    "                couples (path_to_file, label)\n",
    "        \"\"\"\n",
    "        preprocessed_path: Path = (self.mapping / self.name).with_suffix(\".pt\")\n",
    "        if preprocessed_path.exists():\n",
    "            return torch.load(preprocessed_path)\n",
    "        else:\n",
    "            csv_path = (self.mapping / self.name).with_suffix(\".csv\")\n",
    "            if not csv_path.exists():\n",
    "                raise ValueError(f\"Required files do not exist, path: {csv_path}\")\n",
    "            with open(csv_path, encoding=\"utf-8\") as csv_file:\n",
    "                csv_reader = csv.reader(csv_file)\n",
    "                # Ignore header\n",
    "                next(csv_reader)\n",
    "\n",
    "                # Extract the samples and the labels\n",
    "                partition: Sequence[tuple[str, int]] = [\n",
    "                    (sample_path, int(label_id))\n",
    "                    for _, sample_path, _, label_id in csv_reader\n",
    "                ]\n",
    "\n",
    "                # Save for future loading\n",
    "                torch.save(partition, preprocessed_path)\n",
    "                return partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "_o3YKN3UpNmg"
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APf6KKKK5LxV4vm0XUoNNtEsEnktpLtrjUbkwQoiEDAIBLMSeg6Dk10GkXsmo6NY301u1tLcW8crwMcmMsoJU/TOKu0VDPaW100bXFvFKYm3xmRA2xvUZ6GpqKKKKK//2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAlElEQVR4AWL8z4AbMOGWYhhOkiwo/vz3j4EJyecoIfSfEUUpqiTDtR3MPspISv7Dwd9fqcw2wpr//8FFEJK//89h2f7/oeCL/39hssiSPmb//28y+QOXQ5L8828LX3iJyMb/f2Aa/yMczvzfe8sf0ZN+/5nhTkb2yj+QSjABlUaWZEALA1RJwKAa4BTIJDgHnTGMJAGya3ek4aYuBAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset: FEMNIST = FEMNIST(mapping=centralized_mapping, data_dir=data_dir, name=\"train\")\n",
    "\n",
    "# Show random value\n",
    "img, _ = dataset[4]\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zp12GiFVaYXo"
   },
   "source": [
    "Given this fully “centralised” dataset, the client abstraction only requires functions implementing data loading, model training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "URtFwYX0iNSR"
   },
   "outputs": [],
   "source": [
    "# Load with appropriate transforms\n",
    "def to_tensor_transform(p: Any) -> torch.Tensor:\n",
    "    \"\"\"Transform the object given to a PyTorch Tensor.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        p (Any): object to transform.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        torch.Tensor: resulting PyTorch Tensor\n",
    "    \"\"\"\n",
    "    return torch.tensor(p)\n",
    "\n",
    "\n",
    "def load_femnist_dataset(mapping: Path, name: str) -> Dataset:\n",
    "    \"\"\"Load the FEMNIST dataset given the mapping .csv file.\n",
    "\n",
    "    The relevant transforms are automatically applied.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        mapping (Path): path to the mapping .csv file chosen.\n",
    "        name (str): name of the dataset to load, train or test.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Dataset: FEMNIST dataset object, ready-to-use.\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    return FEMNIST(\n",
    "        mapping=mapping,\n",
    "        name=name,\n",
    "        data_dir=data_dir,\n",
    "        transform=transform,\n",
    "        target_transform=to_tensor_transform,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pnFffXP0FBUB"
   },
   "source": [
    "Partitions in FL datasets may vary in data-per-client by orders of magnitude. While in the “centralised” case, one client holds $O(N)$ samples with $N \\approx 80,5263$, a natural partitioning by image creator ID will result in each client holding $O(m)$ samples with $m \\approx 226$.\n",
    "\n",
    "This points to a more fundamental issue in FL, the unbalanced size of local datasets across clients. Several questions arise when considering the potential orders-of-magnitude gap between clients:\n",
    "1. How do we set the amount of training each client does per round?\n",
    "2. How should we balance the contribution of several clients, given differences in dataset size?\n",
    "\n",
    "The original paper introducing FL, [Communication-Efficient Learning of Deep Networks from Decentralized Data](https://arxiv.org/abs/1602.05629), and the Federated Averaging algorithm we shall use today answers the questions in the following ways:\n",
    "1. Set a number of local epochs homogenous across clients; each client iterates over their entire dataset for the provided number of epochs.\n",
    "2. When combining the models of different clients, weigh them by the size of the local dataset of the clients.\n",
    "\n",
    "For now, we shall choose to keep the local epoch design and place an absolute upper limit on the number of batches seen during training/testing due to the computational constraints of training the centralised client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Z2ItflSDFBUC"
   },
   "outputs": [],
   "source": [
    "max_train_batches_per_epoch: int = 100\n",
    "max_test_batches_per_epoch: int = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOXB6EkiFBUC"
   },
   "source": [
    "---\n",
    "\n",
    "**Question 2 (Part II ✅ | Part III/MPhil ✅):**\n",
    "\n",
    "(This is meant to be a conceptual question. You should provide written answers for this. **No more than 3 sentences**. **No code** is needed)\n",
    "\n",
    "Consider the three following scenarios for a population of five clients and identify how weighing client updates by the number of samples compares to unweighted averaging:\n",
    "1. Clients have the same number of samples\n",
    "2. One client has 50% of the samples, and they are of high quality (e.g., coherent English text)\n",
    "3. One client has 50% of the samples, and they are of very low quality (e.g., incomprehensible mashup of letters)\n",
    "\n",
    "---\n",
    "**Question 2 Answer:**\n",
    "\n",
    "1. If the clients have the same number of samples (assuming with the same quality), then weighing client updates by the number of samples would be the same as unweighted averaging since the weights would be the same for all the clients.\n",
    "2. In the second scenario the weighting would give more importance/weight to the client with high-quality samples which would lead to faster convergence than unweighted averaging and potentially a better model .\n",
    "3. In the third scenario, the weighting would give more importance/weight to the client with low-quality samples which would lead to slower convergence than unweighted averaging and potentially a worse model/ no convergence due to the constant update of the model with low-quality samples.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Question 3 (Part III/MPhil ✅):**\n",
    "\n",
    "(This is meant to be a conceptual question. You should provide written answers for this. **No more than 3 sentences**. **No code** is needed)\n",
    "1. In the previous three scenarios, what would happen if we set a homogenous number of training steps for all clients instead of epochs? I.e., clients loop over their dataset until the precise moment when they have processed N total samples.\n",
    "\n",
    "---\n",
    "\n",
    "**Question 3 Answer:**\n",
    "\n",
    "If all clients process exactly N samples (regardless of their dataset size), each client contributes the same amount of training data to the global model, reducing the impact of client dataset size differences. This means that the benefits or drawbacks of having a client with 50% of the total samples –– whether the samples are high or low quality–– is less significant, similarly to unweighted average, because their relative contribution is capped by the fixed number of samples processed. However, this approach can lead to issues such as overfitting for clients with smaller datasets that must loop over their data repeatedly to reach N samples. \n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YYcbCW4FBUC"
   },
   "source": [
    "While FL may use any training function that centralised ML can, there is an extra consideration regarding how much information a client may leak regarding their local dataset. For example, the model may contain enough data to recreate local samples perfectly under the right circumstances unless defensive measures are employed.\n",
    "\n",
    "Later labs and lectures will explore several methods for mitigating such concerns. Until then, the three following pieces of information are currently considered acceptable from a privacy standpoint:\n",
    "1. Model weights.\n",
    "2. The size of the local dataset.\n",
    "3. Cumulative loss values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "fyX641rBkYiv"
   },
   "outputs": [],
   "source": [
    "def train_femnist(\n",
    "    net: Module,\n",
    "    train_loader: DataLoader,\n",
    "    epochs: int,\n",
    "    device: str,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion: Module,\n",
    ") -> float:\n",
    "    \"\"\"Trains the network on the training set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        net (Module): generic module object describing the network to train.\n",
    "        train_loader (DataLoader): dataloader to iterate during the training.\n",
    "        epochs (int): number of epochs of training.\n",
    "        device (str): device name onto which perform the computation.\n",
    "        optimizer (torch.optim.Optimizer): optimizer object.\n",
    "        criterion (Module): generic module describing the loss function.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        float: the final epoch mean train loss.\n",
    "    \"\"\"\n",
    "    net.train()\n",
    "    running_loss, total = 0.0, 0\n",
    "    for _ in tqdm(range(epochs)):\n",
    "        running_loss = 0.0\n",
    "        total = 0\n",
    "        for batch_cnt, (data, labels) in enumerate(train_loader):\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            _outputs = net(data)\n",
    "            loss = criterion(net(data), labels)\n",
    "            running_loss += loss.item()\n",
    "            total += labels.size(0)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Break if we have exceeded the upper limit\n",
    "            # On training batches for a given round\n",
    "            # Simulate enumerate counting for train/test parity\n",
    "            if batch_cnt > max_train_batches_per_epoch:\n",
    "                break\n",
    "    return running_loss / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "TmFKmWHLkl-Z"
   },
   "outputs": [],
   "source": [
    "def test_femnist(\n",
    "    net: Module,\n",
    "    test_loader: DataLoader,\n",
    "    device: str,\n",
    "    criterion: Module,\n",
    ") -> tuple[float, float]:\n",
    "    \"\"\"Validate the network on a test set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        net (Module): generic module object describing the network to test.\n",
    "        test_loader (DataLoader): dataloader to iterate during the testing.\n",
    "        device (str):  device name onto which perform the computation.\n",
    "        criterion (Module): generic module describing the loss function.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        tuple[float, float]: couple of average test loss and average accuracy on the\n",
    "            test set.\n",
    "    \"\"\"\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (data, labels) in enumerate(\n",
    "            tqdm(test_loader, total=min(max_test_batches_per_epoch, len(test_loader)))\n",
    "        ):\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            outputs = net(data)\n",
    "\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Break if we have exceed the upper limit\n",
    "            # On testing batches\n",
    "            if i > max_test_batches_per_epoch:\n",
    "                break\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "LWzf1Z9Q40ia"
   },
   "outputs": [],
   "source": [
    "class CompleteSimpleClient(SimpleClient):\n",
    "    \"\"\"Complete SimpleClient for FEMNIST dataset.\"\"\"\n",
    "\n",
    "    def _load_dataset(self, name: str, config: dict[str, Any]) -> Dataset:\n",
    "        full_file: Path = self.partition_dir / self.cid\n",
    "        return load_femnist_dataset(mapping=full_file, name=name)\n",
    "\n",
    "    def _train(\n",
    "        self, net: Module, train_loader: DataLoader, config: dict[str, Any]\n",
    "    ) -> float:\n",
    "        # Notice the usage of the config dict to obtain training\n",
    "        # parameters for a given client\n",
    "        return train_femnist(\n",
    "            net=net,\n",
    "            train_loader=train_loader,\n",
    "            epochs=config[\"epochs\"],\n",
    "            device=self.device,\n",
    "            optimizer=torch.optim.AdamW(\n",
    "                net.parameters(),\n",
    "                lr=config[\"client_learning_rate\"],\n",
    "                weight_decay=config[\"weight_decay\"],\n",
    "            ),\n",
    "            criterion=torch.nn.CrossEntropyLoss(),\n",
    "        )\n",
    "\n",
    "    def _test(\n",
    "        self, net: Module, test_loader: DataLoader, config: dict[str, Any]\n",
    "    ) -> tuple[float, float]:\n",
    "        return test_femnist(\n",
    "            net=net,\n",
    "            test_loader=test_loader,\n",
    "            device=self.device,\n",
    "            criterion=torch.nn.CrossEntropyLoss(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Asc5DtAN5zXu"
   },
   "source": [
    "This client can now encapsulate any partition of the FEMNIST dataset and train and test on it. To put it into action, we shall define a small CNN taken from the [60 minute PyTorch tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#define-a-convolutional-neural-network) and the training/testing configurations used by the fit/evaluate functions of the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "9khkMcJ142cX"
   },
   "outputs": [],
   "source": [
    "# Define a simple CNN\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"Simple CNN for FEMNIST dataset.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(256, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 62)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass of the network.\"\"\"\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTGpzOTdFBUC"
   },
   "source": [
    "The following global variables will be set to standardise training and testing across experiments. This means fixing:\n",
    "- The starting initialised model.\n",
    "- Local train/test parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "wmsbBUGyFBUC"
   },
   "outputs": [],
   "source": [
    "# All experiments will have the same initialisation.\n",
    "# All differences in performance will come from training\n",
    "\n",
    "\n",
    "def get_network_generator() -> Callable[[], Net]:\n",
    "    \"\"\"Get function to generate a new untrained network.\"\"\"\n",
    "    untrained_net: Net = Net()\n",
    "\n",
    "    def generated_net() -> Net:\n",
    "        return deepcopy(untrained_net)\n",
    "\n",
    "    return generated_net\n",
    "\n",
    "\n",
    "network_generator = get_network_generator()\n",
    "\n",
    "centralized_train_config: dict[str, Any] = {\n",
    "    \"epochs\": 5,\n",
    "    \"batch_size\": 32,\n",
    "    \"client_learning_rate\": 0.01,\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"num_workers\": 0,\n",
    "}\n",
    "\n",
    "test_config: dict[str, Any] = {\n",
    "    \"batch_size\": 32,\n",
    "    \"num_workers\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "0cV3STZ16vYx"
   },
   "outputs": [],
   "source": [
    "# Instantiate the centralised client and model\n",
    "centralized_client = CompleteSimpleClient(cid=0, partition_dir=centralized_partition)\n",
    "centralized_net = network_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "UOEKuiCQ6KVR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:15<00:00,  3.02s/it]\n",
      "INFO flwr 2025-02-07 10:31:50,898 | 565435651.py:5 | Fit results = [20189, {}]\n"
     ]
    }
   ],
   "source": [
    "# Fit the centralised model\n",
    "centralized_net, *rest = fit_client_seeded(\n",
    "    centralized_client, params=centralized_net, conf=centralized_train_config\n",
    ")\n",
    "log(INFO, \"Fit results = %s\", rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Jj4rAKSx6s8q"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:02, 45.71it/s]                        \n",
      "INFO flwr 2025-02-07 10:31:56,463 | 2490435715.py:3 | Test results = (169.70517790317535, 2329, {'local_accuracy': 0.5392156862745098})\n"
     ]
    }
   ],
   "source": [
    "# Test the trained centralised model\n",
    "result = centralized_client.evaluate(net=centralized_net, config=test_config)\n",
    "log(INFO, \"Test results = %s\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INODwg_gVyY2"
   },
   "source": [
    "---\n",
    "\n",
    "**Question 4 (Part II ✅ | Part III/MPhil ✅):**\n",
    "\n",
    "(This is meant to be a conceptual question. You should provide written answers for this. **No more than 3 sentences**. **No code** is needed)\n",
    "\n",
    "1. Read about [data-parallelism](https://d2l.ai/chapter_computational-performance/multiple-gpus.html), if we were to train the centralized model in a data-parallel fashion how often would we need to communicate between the model replicas?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Question 4 Answer:**\n",
    "\n",
    "In data-parallelism, the model replicas communicate and synchronize their gradients after each mini-batch of data is processed. If we were adapt this strategy in a federated learning setting, that would require communication between the server and model replicas after each epoch. This would result in a high communication cost and could slow down the training process/ convergence of the model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7RxdrTSpuXEE"
   },
   "source": [
    "## END OF PART I:\n",
    "\n",
    "Continue to the part 2 notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uE4qbA0rQN69"
   },
   "source": [
    "(c) 2025 Alexandru-Andrei Iacob, Lorenzo Sani"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
